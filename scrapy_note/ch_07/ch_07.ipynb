{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.07 ScrapyとMySQL\n",
    "\n",
    "<https://sugiaki1989.gitbook.io/scrapy-note/chapter07_mysql>\n",
    "\n",
    "[Books to scrape](http://books.toscrape.com/)\n",
    "\n",
    "- MySQLをSQLiteに変更する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロジェクトの作成\n",
    "\n",
    "```bash\n",
    "scrapy startproject sample_books_sqlite\n",
    "\n",
    "cd sample_books_sqlite\n",
    "\n",
    "scrapy genspider books_spider_sqlite books.toscrape.com\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アイテムの定義（SQLite）\n",
    "\n",
    "- items.py\n",
    "- Itemは、スクレイピングしたデータを格納しておくためのオブジェクト\n",
    "- Itemに格納して、SQLiteに保存するためのパイプラインにデータを流す\n",
    "\n",
    "```python\n",
    "# items.py\n",
    "import scrapy\n",
    "\n",
    "class BooksSqliteItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    price = scrapy.Field()\n",
    "    detail_page_url = scrapy.Field()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クローラーの設計\n",
    "\n",
    "```bash\n",
    "scrapy shell https://books.toscrape.com\n",
    "```\n",
    "\n",
    "```bash\n",
    ">>> response.xpath('.//*[@class=\"product_pod\"]')\n",
    "[<Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>, <Selector query='.//*[@class=\"product_pod\"]' data='<article class=\"product_pod\">\\n       ...'>]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# books_spider_sqlite.py\n",
    "from scrapy import Spider\n",
    "from scrapy.http import Request\n",
    "from sample_books_sqlite.items import BooksSqliteItem\n",
    "\n",
    "\n",
    "class BooksSpiderSqliteSpider(Spider):\n",
    "    name = \"books_spider_sqlite\"\n",
    "    allowed_domains = [\"books.toscrape.com\"]\n",
    "    start_urls = [\"https://books.toscrape.com\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        books = response.xpath('.//*[@class=\"product_pod\"]')\n",
    "        for book in books:\n",
    "            item = BooksSqliteItem()\n",
    "\n",
    "            item[\"title\"] = book.xpath('.//h3/a/@title').get()\n",
    "            item[\"price\"] = book.xpath('.//*[@class=\"price_color\"]/text()').get()\n",
    "            img_url = book.xpath('.//*[class=\"image_container\"]/a/@href').get()\n",
    "            item[\"detail_page_url\"] = response.urljoin(img_url)\n",
    "\n",
    "            yield item\n",
    "\n",
    "        # If there is a next button on this page, move the crawler\n",
    "        # このページに「Next」ボタンがある場合は、クローラーを移動させる。\n",
    "        next_page_url = response.xpath('//a[text()=\"next\"]/@href').get()\n",
    "        abs_next_page_url = response.urljoin(next_page_url)\n",
    "        if abs_next_page_url is not None:\n",
    "            yield Request(abs_next_page_url, callback=self.parse)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプラインの設計\n",
    "\n",
    "- pipelines.py\n",
    "- Itemに保存されているデータをSQLiteにインサートするためのパイプライン\n",
    "  - データベースにコネクションを作る関数\n",
    "  - データベースに重複チェックしてインサートする関数\n",
    "  - データベースのコネクションをクロースする関数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pipelines.py\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class BooksSqlitePipeline:\n",
    "    def open_spider(self, spider) -> None:\n",
    "        # Create/Connect to database\n",
    "        self.connection = sqlite3.connect(\"book_online.db\")\n",
    "        # Create cursor\n",
    "        self.cursor = self.connection.cursor()\n",
    "        # booksテーブルが存在しない場合は作成する\n",
    "        self.cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS books(\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                price TEXT,\n",
    "                detail_page_url TEXT,\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        # titleがすでにテーブルにあるかどうかをチェックする\n",
    "        self.cursor.execute(\"select * from books where title = ?\", (item[\"title\"],))\n",
    "        result = self.cursor.fetchone()\n",
    "\n",
    "        # テーブルにある場合は、ログメッセージを作成する\n",
    "        if result:\n",
    "            spider.logger.warn(\"Item already in table: %s\" % item[\"title\"])\n",
    "        # テーブルにtitleがない場合、データを挿入する\n",
    "        else:\n",
    "            # insertステートメントの定義\n",
    "            self.cursor.execute(\n",
    "                \"\"\"INSERT INTO books (title, price, detail_page_url) VALUES (?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    item[\"title\"],\n",
    "                    item[\"price\"],\n",
    "                    item[\"detail_page_url\"],\n",
    "                )\n",
    "            )\n",
    "            # テーブルへのデータ挿入の実行\n",
    "            self.connection.commit()\n",
    "\n",
    "        return item\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.connection.close()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設定\n",
    "\n",
    "- settings.py\n",
    "- パイプラインを有効にする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# settings.py\n",
    "# Configure item pipelines\n",
    "# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "ITEM_PIPELINES = {\n",
    "   \"sample_books_sqlite.pipelines.BooksSqlitePipeline\": 800,\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クローラーの実行\n",
    "\n",
    "```bash\n",
    "scrapy crawl books_spider_sqlite\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
